\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Abstract}{1}{Doc-Start}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Contents}{1}{chapter*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Figures}{2}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Tables}{3}{chapter*.3}\protected@file@percent }
\citation{Balachandran2009}
\citation{Saisubramanian2019}
\citation{Ozyegen2022}
\citation{Plant2011}
\citation{Tjoa2023}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{4}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background}{4}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Research Objectives}{5}{section.1.2}\protected@file@percent }
\citation{Miklautz2021}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{6}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Deep Embedded Clustering with Consensus Representations (DECCS)}{6}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Related Work in Consensus Clustering and Deep Clustering}{6}{subsection.2.1.1}\protected@file@percent }
\citation{Xie2016}
\citation{Kingma2014}
\citation{Miklautz2021}
\citation{Miklautz2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Methodology of DECCS}{7}{subsection.2.1.2}\protected@file@percent }
\citation{Zhang2021}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Visualisation of one round of DECCS\citep  {Miklautz2021}. (1) The encoder is used to embed data points $X$. (2) Clustering results are generated by applying ensemble members $\mathcal  {E} = \{KM, \ldots  , SC\}$ to $Z$. (3) Classifiers $g_i$ are trained to predict the corresponding cluster labels $\pi _i$ from $Z$. (4) $Z$ is updated via minimizing $\mathcal  {L}$.}}{8}{figure.2.1}\protected@file@percent }
\newlabel{fig:pipeline}{{2.1}{8}{Visualisation of one round of DECCS\citep {Miklautz2021}. (1) The encoder is used to embed data points $X$. (2) Clustering results are generated by applying ensemble members $\mathcal {E} = \{KM, \ldots , SC\}$ to $Z$. (3) Classifiers $g_i$ are trained to predict the corresponding cluster labels $\pi _i$ from $Z$. (4) $Z$ is updated via minimizing $\mathcal {L}$}{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Experimental Evaluation}{8}{subsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Deep Descriptive Clustering (DDC)}{8}{section.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The framework of deep descriptive clustering (DDC). DDC consists of one clustering objective, one sub-symbolic explanation objective, and one self-generated objective to maximize the consistency between clustering and explanation modules.}}{9}{figure.2.2}\protected@file@percent }
\newlabel{fig:ddc}{{2.2}{9}{The framework of deep descriptive clustering (DDC). DDC consists of one clustering objective, one sub-symbolic explanation objective, and one self-generated objective to maximize the consistency between clustering and explanation modules}{figure.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Key Aspects of Deep Descriptive Clustering (DDC)}{9}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Experiments and Findings}{9}{subsection.2.2.2}\protected@file@percent }
\citation{Xie2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Conclusion and Future Directions}{10}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Related Works}{10}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Deep Embedded Clustering: A General Approach to Clustering Arbitrary Similarity Measures by J. Xie, R. Girshick, and A. Farhadi (2016)}{10}{subsection.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Architecture of the Deep Embedded Clustering (DEC) model. The model consists of a stacked autoencoder followed by a clustering layer. The autoencoder learns a low-dimensional representation of the data, which is then clustered using a clustering objective.}}{10}{figure.2.3}\protected@file@percent }
\newlabel{fig:dec_architecture}{{2.3}{10}{Architecture of the Deep Embedded Clustering (DEC) model. The model consists of a stacked autoencoder followed by a clustering layer. The autoencoder learns a low-dimensional representation of the data, which is then clustered using a clustering objective}{figure.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Auto-Encoding Variational Bayes by D. P. Kingma and M. Welling (2014)}{10}{subsection.2.3.2}\protected@file@percent }
\citation{Kingma2014}
\citation{Sambaturu2020}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Architecture of the Variational Autoencoder (VAE) model. The encoder maps input data to a latent space, and the decoder reconstructs the data from the latent space. The model is trained to minimize reconstruction loss and regularization loss.}}{11}{figure.2.4}\protected@file@percent }
\newlabel{fig:vae_architecture}{{2.4}{11}{Architecture of the Variational Autoencoder (VAE) model. The encoder maps input data to a latent space, and the decoder reconstructs the data from the latent space. The model is trained to minimize reconstruction loss and regularization loss}{figure.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Explainable-by-Design Algorithms}{11}{subsection.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Post-processing Explanation Methods}{11}{subsection.2.3.4}\protected@file@percent }
\citation{Rishinanda2021,Liu2022,Chhajer2022}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Other Related Works}{12}{subsection.2.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{13}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Methodology}{14}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Overview}{14}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Initial Clustering with DECCS}{14}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Generating Explanations with DDC}{14}{section.4.3}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Generating Explanations with DDC}}{15}{algorithm.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Dataset Preparation}{15}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}AwA2 Dataset}{15}{subsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Data Preprocessing}{15}{subsection.4.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Model Training}{15}{section.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Autoencoder}{15}{subsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Embedding Extraction}{16}{subsection.4.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Clustering}{16}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}K-Means Clustering}{16}{subsection.4.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Validation and Analysis}{17}{subsection.4.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Integration of Pairwise Loss Function}{17}{section.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Balancing Loss Components}{17}{section.4.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.9}Iterative Optimization and Refinement}{18}{section.4.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.10}Finalization of the Model}{18}{section.4.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.11}Performance and Interpretability Evaluation}{18}{section.4.11}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results}{19}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Discussion}{20}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion}{21}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendix A}{22}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibstyle{plainnat}
\bibdata{bibliography}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Appendix B}{23}{appendix.B}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\gdef \@abspage@last{25}
