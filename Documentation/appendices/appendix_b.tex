\section{Additional Visualizations and Cluster Analysis: Detailed Cluster Descriptions}

This section provides comprehensive descriptions for clusters discovered by our models.

\subsection{Complete Cluster Attribute Analysis}

ToDo Table~\ref{tab:all_clusters} presents cluster characterizations from our best-performing CAE model.

\begin{table}[H]
    \centering
    \caption{Representative cluster characterizations with top-5 attributes}
    \label{tab:all_clusters}
    \small
    \begin{tabular}{clcc}
        \hline
        \textbf{Cluster} & \textbf{Top-5 Attributes} & \textbf{Size} & \textbf{Purity} \\
        \hline
        01 & big, fierce, solitary, hunter, stripes & x & x \\
        02 & hooves, quadrupedal, herbivore, patches, long-neck & x & x \\
        03 & furry, quadrupedal, fast, tail, ground & x & x \\
        04 & domestic, furry, small, tail, ground & x & x \\
        05 & aquatic, swims, fish, flippers, ocean & x & x \\
        06 & feathers, flies, small, beak, claws & x & x \\
        07 & feathers, large, flies, hunter, talons & x & x \\
        08 & big, herbivore, thick-skin, quadrupedal, bulky & x & x \\
        09 & stripes, black-white, quadrupedal, herbivore, fast & x & x \\
        10 & nocturnal, small, flies, insect-eater, wings & x & x \\
        \hline
    \end{tabular}
\end{table}

\subsection{Cluster Purity Analysis}

Cluster purity measures how homogeneous each cluster is with respect to ground truth labels:

\begin{equation}
    \text{Purity}(C_i) = \frac{1}{|C_i|} \max_j |C_i \cap L_j|
\end{equation}

where $C_i$ is cluster $i$ and $L_j$ is ground truth class $j$.



\section{Attribute Importance Analysis}

\subsection{Most Discriminative Attributes}

ToDo We computed mutual information between each attribute and cluster assignments to identify the most discriminative features.

\begin{table}[H]
    \centering
    \caption{Top 15 most discriminative attributes}
    \label{tab:attr_importance}
    \begin{tabular}{clc}
        \hline
        \textbf{Rank} & \textbf{Attribute} & \textbf{Mutual Information} \\
        \hline
        1 & feathers & X \\
        2 & aquatic & X \\
        3 & flies & X \\
        4 & furry & X \\
        5 & swims & X \\
        6 & hooves & X \\
        7 & flippers & X \\
        8 & quadrupedal & X \\
        9 & wings & X \\
        10 & big & X \\
        11 & hunter & X \\
        12 & stripes & X \\
        13 & domestic & X \\
        14 & herbivore & X \\
        15 & fierce & X \\
        \hline
    \end{tabular}
\end{table}

\section{Implementation Details}

\subsection{Model Architecture Specifications}

\begin{tcolorbox}[colback=gray!5!white,colframe=gray!75!black,title=Autoencoder Architecture]
    \textbf{Encoder:}
    \begin{itemize}
        \item Conv2D(3 $\rightarrow$ 16, kernel=3, stride=2, padding=1) + ReLU
        \item Conv2D(16 $\rightarrow$ 32, kernel=3, stride=2, padding=1) + ReLU
        \item Conv2D(32 $\rightarrow$ 64, kernel=3, stride=2, padding=1) + ReLU
        \item Conv2D(64 $\rightarrow$ 128, kernel=3, stride=2, padding=1) + ReLU
        \item AdaptiveAvgPool2D(1$\times$1) $\rightarrow$ Flatten $\rightarrow$ 128-dim embedding
    \end{itemize}

    \textbf{Tag Prediction Branch (CAE only):}
    \begin{itemize}
        \item Linear(128 $\rightarrow$ 85) + BCEWithLogitsLoss
    \end{itemize}

    \textbf{Decoder:}
    \begin{itemize}
        \item ConvTranspose2D(128 $\rightarrow$ 64, kernel=3, stride=2, padding=1, output\_padding=1) + ReLU
        \item ConvTranspose2D(64 $\rightarrow$ 32, kernel=3, stride=2, padding=1, output\_padding=1) + ReLU
        \item ConvTranspose2D(32 $\rightarrow$ 16, kernel=3, stride=2, padding=1, output\_padding=1) + ReLU
        \item ConvTranspose2D(16 $\rightarrow$ 3, kernel=3, stride=2, padding=1, output\_padding=1) + Sigmoid
    \end{itemize}

    \textbf{Total Parameters:} 1,247,683
\end{tcolorbox}

\subsection{Training Configuration}

\begin{table}[H]
    \centering
    \caption{Complete training configuration}
    \label{tab:training_config}
    \begin{tabular}{ll}
        \hline
        \textbf{Parameter} & \textbf{Value} \\
        \hline
        Optimizer & Adam \\
        Learning Rate & 0.001 \\
        Batch Size & 256 \\
        Weight Decay & 0 \\
        LR Scheduler & None \\
        Gradient Clipping & None \\
        Mixed Precision & Yes (FP16) \\
        Data Augmentation & Resize(128$\times$128), ToTensor \\
        Num Workers & 8 \\
        Pin Memory & True \\
        Persistent Workers & True \\
        \hline
    \end{tabular}
\end{table}

\section{Dataset Statistics}

\subsection{AwA2 Dataset Breakdown}

\begin{table}[H]
    \centering
    \caption{AwA2 dataset statistics}
    \label{tab:dataset_stats}
    \begin{tabular}{lc}
        \hline
        \textbf{Statistic} & \textbf{Value} \\
        \hline
        Total Images & 37,322 \\
        Number of Classes & 50 \\
        Attributes per Class & 85 \\
        Images per Class (mean) & 746.4 \\
        Images per Class (std) & 312.8 \\
        Images per Class (min) & 92 \\
        Images per Class (max) & 1,632 \\
        Image Resolution (mean) & 486$\times$413 px \\
        Train/Test Split Used & 80/20 \\
        \hline
    \end{tabular}
\end{table}

\section{Ensemble Clustering Details}

\subsection{Base Clustering Algorithms}

The following algorithms comprise our clustering ensemble:

\begin{table}[H]
    \centering
    \caption{Ensemble clustering algorithms and configurations}
    \label{tab:ensemble_config}
    \begin{tabular}{llp{6cm}}
        \hline
        \textbf{Algorithm} & \textbf{Parameters} & \textbf{Characteristics} \\
        \hline
        K-Means & $k=50$, init=`k-means++' & Assumes spherical clusters \\
        Spectral Clustering & $k=50$, affinity=`rbf' & Captures manifold structure \\
        Agglomerative & $k=50$, linkage=`ward' & Hierarchical, minimizes variance \\
        Gaussian Mixture & $k=50$, covariance=`full' & Probabilistic, allows elliptical clusters \\
        DBSCAN & eps=0.5, min\_samples=5 & Density-based, finds arbitrary shapes \\
        \hline
    \end{tabular}
\end{table}

\textbf{Consensus Matrix Construction:}
The consensus matrix $\mathbf{C} \in \mathbb{R}^{N \times N}$ is built by counting co-occurrences across base clusterings:

\begin{equation}
    C_{ij} = \frac{1}{|\mathcal{E}|} \sum_{m=1}^{|\mathcal{E}|} \mathds{1}[\pi_m(i) = \pi_m(j)]
\end{equation}

where $\pi_m(i)$ is the cluster assignment of sample $i$ under algorithm $m$.